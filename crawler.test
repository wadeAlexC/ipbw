// package crawler

// import (
// 	"bytes"
// 	"context"
// 	"crypto/rand"
// 	"encoding/json"
// 	"fmt"
// 	"io/ioutil"
// 	"net"
// 	"net/http"
// 	"strings"
// 	"sync"
// 	"time"

// 	"github.com/ipfs/go-datastore"
// 	badger "github.com/ipfs/go-ds-badger"
// 	"github.com/libp2p/go-libp2p"
// 	"github.com/libp2p/go-libp2p-core/peer"
// 	"github.com/libp2p/go-libp2p-core/routing"
// 	host "github.com/libp2p/go-libp2p-host"
// 	dht "github.com/libp2p/go-libp2p-kad-dht"
// 	"github.com/libp2p/go-libp2p/p2p/protocol/identify"
// 	ma "github.com/multiformats/go-multiaddr"
// 	mh "github.com/multiformats/go-multihash"
// )

// // Crawler holds info about an active crawl
// type Crawler struct {
// 	// IPFS / libp2p fields
// 	host host.Host
// 	dht  *dht.IpfsDHT
// 	ds   datastore.Batching
// 	id   *identify.IDService

// 	// We receive QueryEvents from the DHT on this channel
// 	events <-chan *routing.QueryEvent
// 	report *Report // Result aggregator

// 	// Context and cancel function passed to DHT queries
// 	ctx    context.Context
// 	cancel context.CancelFunc
// 	wg     sync.WaitGroup

// 	opts *Options
// }

// // Report aggregates results from QueryEvents
// type Report struct {
// 	mu    sync.RWMutex
// 	peers map[peer.ID]*Peer
// }

// // Peer contains all the info we know for a given peer
// type Peer struct {
// 	isReporter bool      // Whether this peer reported other peers to us
// 	ips        []string  // All known IPs/ports for this peer
// 	neighbors  []peer.ID // All neighbors this peer reported to us
// 	timestamp  string    // The UTC timestamp when we discovered the peer
// }

// // Options are various configurations for the crawler
// type Options struct {
// 	NoPublish       bool   // Whether we're publishing reports to a server
// 	PublishInterval uint   // How often a report is sent to our server
// 	ReportInterval  uint   // How often a report will be printed to the console
// 	NumWorkers      uint   // Number of goroutines to query the DHT with
// 	Server          string // Endpoint to publish results to
// 	ServerPing      string // Endpoint to check if server is running
// }

// // Start spawns all the goroutines we need for world domination
// func (c *Crawler) Start() {
// 	for i := 0; i < int(c.opts.NumWorkers); i++ {
// 		c.wg.Add(1)
// 		go c.worker() // Queries DHT
// 	}

// 	go c.aggregator() // Collects results from c.events
// 	go c.logger()     // Prints intermittent status updates to console
// 	if !c.opts.NoPublish {
// 		go c.reporter() // Publishes results to server
// 	}
// }

// // Stop stops the crawl, but waits briefly to allow tasks to finish
// func (c *Crawler) Stop() {
// 	// 5 seconds is the empirically-derived correct time to wait
// 	waitTime := time.Duration(5) * time.Second

// 	select {
// 	case <-time.After(waitTime):
// 		c.Kill()
// 		return
// 	}
// }

// // Kill stops the crawl ASAP
// func (c *Crawler) Kill() {
// 	if err := c.ds.Close(); err != nil {
// 		fmt.Printf("error while shutting down: %v\n", err)
// 	}

// 	c.cancel()
// 	c.wg.Done()
// }

// // Publishes reports to a server
// func (c *Crawler) reporter() {
// 	publishInterval := time.Duration(c.opts.PublishInterval) * time.Minute
// 	for {
// 		select {
// 		case <-time.After(publishInterval):
// 			if c.opts.NoPublish {
// 				continue
// 			}

// 			// Send report to server
// 			response, err := c.publishResults()
// 			if err != nil {
// 				fmt.Printf("Error publishing result: %v\n", err)
// 			} else {
// 				fmt.Printf("Sent report to (%s) and got response: %s\n", c.opts.Server, response)
// 			}
// 		case <-c.ctx.Done():
// 			return
// 		}
// 	}
// }

// // PeerJSON is a json-marshallable form of Peer (with an added pid field)
// type PeerJSON struct {
// 	Pid       string   `json:"pid"`
// 	Ips       []string `json:"ips"`
// 	Neighbors []string `json:"neighbors"`
// 	Timestamp string   `json:"timestamp"`
// }

// // ReportJSON is a json-marshallable form of Report
// type ReportJSON struct {
// 	Peers []PeerJSON `json:"peers"`
// }

// // Convert current report to JSON and send to server
// func (c *Crawler) publishResults() (string, error) {
// 	reportJSON := &ReportJSON{
// 		Peers: make([]PeerJSON, 0),
// 	}

// 	c.report.mu.Lock() // Lock report for writes so we can read

// 	for id, peer := range c.report.peers {
// 		// Convert neighbor IDs to strings
// 		neighborStrings := make([]string, len(peer.neighbors))
// 		for _, neighbor := range peer.neighbors {
// 			neighborStrings = append(neighborStrings, neighbor.Pretty())
// 		}

// 		// Convert peer to PeerJSON
// 		peerJSON := PeerJSON{
// 			Pid:       id.Pretty(),
// 			Ips:       peer.ips,
// 			Neighbors: neighborStrings,
// 			Timestamp: peer.timestamp,
// 		}

// 		reportJSON.Peers = append(reportJSON.Peers, peerJSON)
// 	}
// 	c.report.mu.Unlock()

// 	reportBody, err := json.Marshal(reportJSON)
// 	if err != nil {
// 		return "", err
// 	}

// 	resp, err := http.Post(c.opts.Server, "application/json", bytes.NewBuffer(reportBody))
// 	if err != nil {
// 		return "", err
// 	}
// 	defer resp.Body.Close()

// 	body, err := ioutil.ReadAll(resp.Body)
// 	if err != nil {
// 		return "", err
// 	}

// 	return string(body), nil
// }

// func (c *Crawler) pingServer() (string, error) {
// 	resp, err := http.Get(c.opts.ServerPing)
// 	if err != nil {
// 		return "", err
// 	}

// 	defer resp.Body.Close()

// 	body, err := ioutil.ReadAll(resp.Body)
// 	if err != nil {
// 		return "", err
// 	}

// 	return string(body), nil
// }
